{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260e576c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34c2af27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3070\n",
      "Kullanılan Cihaz: cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "# --- Yapılandırma Parametreleri ---\n",
    "\n",
    "# Veri Yolları\n",
    "DATA_DIR = '../data/fashion-dataset/'\n",
    "CSV_FILE = os.path.join(DATA_DIR, 'styles.csv')\n",
    "IMAGES_DIR = os.path.join(DATA_DIR, 'images')\n",
    "\n",
    "# Model Parametreleri\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_WORKERS = 2 # Veri yükleme hızını artırır\n",
    "\n",
    "# Cihaz (GPU varsa kullanır)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Kullanılan Cihaz: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6512c156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam 44419 adet kullanılabilir resim bulundu.\n",
      "Toplam 7 adet ana kategori var: ['Accessories', 'Apparel', 'Footwear', 'Free Items', 'Home', 'Personal Care', 'Sporting Goods']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_FILE, on_bad_lines='skip')\n",
    "\n",
    "# Kullanılabilir verileri filtrele (resmi olanlar)\n",
    "df['image_path'] = df.apply(lambda row: os.path.join(IMAGES_DIR, str(row['id']) + '.jpg'), axis=1)\n",
    "df = df[df.apply(lambda row: os.path.exists(row['image_path']), axis=1)].copy()\n",
    "\n",
    "# Sınıf etiketlerini sayısal değerlere dönüştürme\n",
    "df['masterCategory_idx'] = df['masterCategory'].astype('category').cat.codes\n",
    "class_to_idx = dict(df[['masterCategory', 'masterCategory_idx']].drop_duplicates().sort_values('masterCategory_idx').values)\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "NUM_CLASSES = len(class_to_idx)\n",
    "\n",
    "print(f\"Toplam {len(df)} adet kullanılabilir resim bulundu.\")\n",
    "print(f\"Toplam {NUM_CLASSES} adet ana kategori var: {list(class_to_idx.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48a1e5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fca754ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.labels = self.df['masterCategory_idx'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['image_path']\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Uyarı: Resim bulunamadı - {img_path}\")\n",
    "            # Hata durumunda geçici bir tensör ve -1 etiketi döndür\n",
    "            return torch.randn(3, 224, 224), -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4071bf90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sınıf dengesizliğini gidermek için sampler oluşturuluyor...\n",
      "Veri yükleyiciler hazır.\n"
     ]
    }
   ],
   "source": [
    "# Veri setini train ve val olarak ayırma\n",
    "train_size = int(0.8 * len(df))\n",
    "val_size = len(df) - train_size\n",
    "# Ayırmanın her zaman aynı sonucu vermesi için bir 'generator' eklemek iyi bir pratiktir\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_df_subset, val_df_subset = random_split(df, [train_size, val_size], generator=generator)\n",
    "\n",
    "# Hata almamak için subset'lerden dataframe'e geçerken index'leri sıfırlayalım\n",
    "train_dataset = FashionDataset(train_df_subset.dataset.iloc[train_df_subset.indices].reset_index(drop=True), transform=data_transforms['train'])\n",
    "val_dataset = FashionDataset(val_df_subset.dataset.iloc[val_df_subset.indices].reset_index(drop=True), transform=data_transforms['val'])\n",
    "\n",
    "# --- Sınıf Dengesizliği için Ağırlıklı Örnekleyici (Weighted Sampler) ---\n",
    "print(\"\\nSınıf dengesizliğini gidermek için sampler oluşturuluyor...\")\n",
    "\n",
    "# 1. Eğitim setindeki her bir sınıfın sayısını hesapla.\n",
    "#    minlength=NUM_CLASSES, dizinin boyutunun her zaman toplam sınıf sayısı kadar olmasını garanti eder.\n",
    "class_counts = np.bincount(train_dataset.labels, minlength=NUM_CLASSES)\n",
    "\n",
    "# 2. Her bir sınıf için ağırlığı hesapla (1 / sayı).\n",
    "#    Sıfıra bölme hatasını önlemek için sayılara çok küçük bir değer (epsilon) ekliyoruz.\n",
    "weights = 1.0 / (class_counts.astype(float) + 1e-6)\n",
    "\n",
    "# 3. Eğitim setindeki her bir örnek için, etiketine karşılık gelen ağırlığı ata.\n",
    "sample_weights = weights[train_dataset.labels]\n",
    "\n",
    "# 4. Ağırlıkları PyTorch tensörüne çevir.\n",
    "sample_weights_tensor = torch.from_numpy(sample_weights).double()\n",
    "\n",
    "# 5. Sampler'ı oluştur.\n",
    "sampler = torch.utils.data.WeightedRandomSampler(weights=sample_weights_tensor, num_samples=len(sample_weights_tensor), replacement=True)\n",
    "\n",
    "# DataLoader'ları oluşturma\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(\"Veri yükleyiciler hazır.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5562d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Önceden eğitilmiş MobileNetV2 modelini yüklüyoruz\n",
    "model = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V2')\n",
    "\n",
    "# Modelin son katmanını (classifier) kendi problemimize (NUM_CLASSES) göre değiştiriyoruz\n",
    "model.classifier[1] = nn.Linear(model.last_channel, NUM_CLASSES)\n",
    "\n",
    "# Modeli seçilen cihaza (GPU/CPU) gönderiyoruz\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Optimizer ve Loss fonksiyonunu tanımlıyoruz\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedba676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Eğitim]:   0%|                                                                                                                                                                                                                                 | 0/556 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "best_val_accuracy = 0.0\n",
    "best_model_path = \"models/fashion_sense_best_model.pth\"\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # --- Eğitim Aşaması ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_corrects = 0\n",
    "    \n",
    "    # tqdm ile ilerleme çubuğu ekliyoruz\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Eğitim]\"):\n",
    "        # Bozuk veriyi atla\n",
    "        if -1 in labels: continue\n",
    "        \n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        train_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_acc = train_corrects.double() / len(train_loader.sampler) # sampler uzunluğu kullanılır\n",
    "\n",
    "    # --- Validasyon Aşaması ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Validasyon]\"):\n",
    "            if -1 in labels: continue\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            val_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "    val_loss = val_loss / len(val_dataset)\n",
    "    val_acc = val_corrects.double() / len(val_dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} -> Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # En iyi modeli kaydetme\n",
    "    if val_acc > best_val_accuracy:\n",
    "        best_val_accuracy = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Yeni en iyi model kaydedildi: {best_model_path} (Doğruluk: {val_acc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d669b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En iyi modelin ağırlıklarını yükle\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(val_loader, desc=\"Son Değerlendirme\"):\n",
    "        if -1 in labels: continue\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Karmaşıklık Matrisini Çizdirme\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(class_to_idx.keys()))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "disp.plot(ax=ax, xticks_rotation='vertical', cmap='Blues')\n",
    "plt.title('Karmaşıklık Matrisi (En İyi Model)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
